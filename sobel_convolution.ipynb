{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhXLQPeB9OBFiS9h4YmBNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyucedemirbas/sobel_conv2d/blob/main/sobel_convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ogEReiHxBa35"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = tf.keras.utils.to_categorical(y_train), tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "p20OlNjpBd_b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32).reshape((3, 3, 1, 1))\n",
        "sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32).reshape((3, 3, 1, 1))"
      ],
      "metadata": {
        "id": "jtiU8YpoBiaJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SobelLayer(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SobelLayer, self).__init__()\n",
        "        # Sobel filters for all input channels\n",
        "        self.sobel_x = tf.constant(sobel_x, dtype=tf.float32)\n",
        "        self.sobel_y = tf.constant(sobel_y, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Expand Sobel filters to match the input's channel dimension\n",
        "        input_channels = inputs.shape[-1]\n",
        "        sobel_x_filter = tf.tile(self.sobel_x, [1, 1, input_channels, 1])\n",
        "        sobel_y_filter = tf.tile(self.sobel_y, [1, 1, input_channels, 1])\n",
        "\n",
        "        # Apply Sobel filters independently to each channel\n",
        "        sobel_x_output = tf.nn.depthwise_conv2d(inputs, sobel_x_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        sobel_y_output = tf.nn.depthwise_conv2d(inputs, sobel_y_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "        # Compute the magnitude of the gradients\n",
        "        sobel_output = tf.sqrt(tf.square(sobel_x_output) + tf.square(sobel_y_output))\n",
        "\n",
        "        # Concatenate Sobel output with the original inputs\n",
        "        return tf.concat([sobel_output, inputs], axis=-1)\n",
        "\n",
        "def create_model():\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    x = SobelLayer()(inputs)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "4S29w3qxBs4G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.trainable = True"
      ],
      "metadata": {
        "id": "FGdwkdvsBvE3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for layer in model.layers:\n",
        "    if i<2:\n",
        "      #print(\"hello\")\n",
        "      layer.trainable = False\n",
        "      i+=1"
      ],
      "metadata": {
        "id": "qche96j5CLYI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zTGqjvnCByGr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsDOMKCxC_Fz",
        "outputId": "ca9e9e17-4e51-453b-9abe-d2de0787dfb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.2950 - loss: 1.8897 - val_accuracy: 0.4524 - val_loss: 1.4960\n",
            "Epoch 2/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4862 - loss: 1.4176 - val_accuracy: 0.5352 - val_loss: 1.2861\n",
            "Epoch 3/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5406 - loss: 1.2703 - val_accuracy: 0.5714 - val_loss: 1.1912\n",
            "Epoch 4/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5809 - loss: 1.1716 - val_accuracy: 0.6005 - val_loss: 1.1158\n",
            "Epoch 5/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 1.0808 - val_accuracy: 0.6287 - val_loss: 1.0520\n",
            "Epoch 6/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6428 - loss: 1.0097 - val_accuracy: 0.6392 - val_loss: 1.0188\n",
            "Epoch 7/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6570 - loss: 0.9743 - val_accuracy: 0.6351 - val_loss: 1.0366\n",
            "Epoch 8/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6742 - loss: 0.9319 - val_accuracy: 0.6786 - val_loss: 0.9225\n",
            "Epoch 9/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 0.8856 - val_accuracy: 0.6886 - val_loss: 0.8992\n",
            "Epoch 10/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 0.8600 - val_accuracy: 0.6853 - val_loss: 0.9036\n",
            "Epoch 11/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7126 - loss: 0.8274 - val_accuracy: 0.6909 - val_loss: 0.8843\n",
            "Epoch 12/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7254 - loss: 0.7928 - val_accuracy: 0.6748 - val_loss: 0.9145\n",
            "Epoch 13/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7364 - loss: 0.7644 - val_accuracy: 0.7179 - val_loss: 0.8166\n",
            "Epoch 14/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.7377 - val_accuracy: 0.7124 - val_loss: 0.8374\n",
            "Epoch 15/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.7151 - val_accuracy: 0.7124 - val_loss: 0.8346\n",
            "Epoch 16/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6869 - val_accuracy: 0.7271 - val_loss: 0.7903\n",
            "Epoch 17/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7676 - loss: 0.6695 - val_accuracy: 0.7160 - val_loss: 0.8204\n",
            "Epoch 18/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.6580 - val_accuracy: 0.7087 - val_loss: 0.8467\n",
            "Epoch 19/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.6326 - val_accuracy: 0.7227 - val_loss: 0.8061\n",
            "Epoch 20/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.6202 - val_accuracy: 0.7466 - val_loss: 0.7468\n",
            "Epoch 21/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7921 - loss: 0.6006 - val_accuracy: 0.7334 - val_loss: 0.7844\n",
            "Epoch 22/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.5765 - val_accuracy: 0.7472 - val_loss: 0.7463\n",
            "Epoch 23/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.5659 - val_accuracy: 0.7396 - val_loss: 0.7731\n",
            "Epoch 24/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.5447 - val_accuracy: 0.7490 - val_loss: 0.7374\n",
            "Epoch 25/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.5350 - val_accuracy: 0.7406 - val_loss: 0.7698\n",
            "Epoch 26/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.5110 - val_accuracy: 0.7454 - val_loss: 0.7615\n",
            "Epoch 27/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.5051 - val_accuracy: 0.7495 - val_loss: 0.7467\n",
            "Epoch 28/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.4870 - val_accuracy: 0.7488 - val_loss: 0.7689\n",
            "Epoch 29/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.4731 - val_accuracy: 0.7642 - val_loss: 0.7236\n",
            "Epoch 30/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.4594 - val_accuracy: 0.7543 - val_loss: 0.7549\n",
            "Epoch 31/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.4519 - val_accuracy: 0.7572 - val_loss: 0.7528\n",
            "Epoch 32/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 0.4273 - val_accuracy: 0.7538 - val_loss: 0.7773\n",
            "Epoch 33/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 0.4135 - val_accuracy: 0.7566 - val_loss: 0.7512\n",
            "Epoch 34/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.4055 - val_accuracy: 0.7611 - val_loss: 0.7440\n",
            "Epoch 35/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8655 - loss: 0.3909 - val_accuracy: 0.7438 - val_loss: 0.7901\n",
            "Epoch 36/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8645 - loss: 0.3899 - val_accuracy: 0.7471 - val_loss: 0.8184\n",
            "Epoch 37/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3731 - val_accuracy: 0.7629 - val_loss: 0.7549\n",
            "Epoch 38/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.3565 - val_accuracy: 0.7487 - val_loss: 0.8019\n",
            "Epoch 39/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.3430 - val_accuracy: 0.7638 - val_loss: 0.7688\n",
            "Epoch 40/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3313 - val_accuracy: 0.7544 - val_loss: 0.8025\n",
            "Epoch 41/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.3266 - val_accuracy: 0.7540 - val_loss: 0.8286\n",
            "Epoch 42/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.3132 - val_accuracy: 0.7504 - val_loss: 0.8319\n",
            "Epoch 43/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2983 - val_accuracy: 0.7516 - val_loss: 0.8450\n",
            "Epoch 44/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.2837 - val_accuracy: 0.7552 - val_loss: 0.8699\n",
            "Epoch 45/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2770 - val_accuracy: 0.7574 - val_loss: 0.8349\n",
            "Epoch 46/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2721 - val_accuracy: 0.7430 - val_loss: 0.9346\n",
            "Epoch 47/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9082 - loss: 0.2642 - val_accuracy: 0.7647 - val_loss: 0.8284\n",
            "Epoch 48/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2458 - val_accuracy: 0.7480 - val_loss: 0.9066\n",
            "Epoch 49/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2426 - val_accuracy: 0.7541 - val_loss: 0.8879\n",
            "Epoch 50/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2349 - val_accuracy: 0.7527 - val_loss: 0.9394\n",
            "Epoch 51/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.2246 - val_accuracy: 0.7537 - val_loss: 0.9572\n",
            "Epoch 52/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2169 - val_accuracy: 0.7493 - val_loss: 0.9341\n",
            "Epoch 53/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9344 - loss: 0.1996 - val_accuracy: 0.7545 - val_loss: 0.9928\n",
            "Epoch 54/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.1987 - val_accuracy: 0.7455 - val_loss: 0.9804\n",
            "Epoch 55/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9321 - loss: 0.1957 - val_accuracy: 0.7455 - val_loss: 1.0644\n",
            "Epoch 56/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.1821 - val_accuracy: 0.7513 - val_loss: 1.0009\n",
            "Epoch 57/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1756 - val_accuracy: 0.7537 - val_loss: 1.0038\n",
            "Epoch 58/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.1674 - val_accuracy: 0.7466 - val_loss: 1.0459\n",
            "Epoch 59/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.1586 - val_accuracy: 0.7495 - val_loss: 1.0281\n",
            "Epoch 60/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1557 - val_accuracy: 0.7572 - val_loss: 1.0706\n",
            "Epoch 61/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1589 - val_accuracy: 0.7398 - val_loss: 1.1363\n",
            "Epoch 62/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1472 - val_accuracy: 0.7524 - val_loss: 1.1126\n",
            "Epoch 63/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.1363 - val_accuracy: 0.7523 - val_loss: 1.1203\n",
            "Epoch 64/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1390 - val_accuracy: 0.7484 - val_loss: 1.1731\n",
            "Epoch 65/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1346 - val_accuracy: 0.7399 - val_loss: 1.2294\n",
            "Epoch 66/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1192 - val_accuracy: 0.7468 - val_loss: 1.2030\n",
            "Epoch 67/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1051 - val_accuracy: 0.7501 - val_loss: 1.2366\n",
            "Epoch 68/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1154 - val_accuracy: 0.7467 - val_loss: 1.2394\n",
            "Epoch 69/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1049 - val_accuracy: 0.7518 - val_loss: 1.2269\n",
            "Epoch 70/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.0970 - val_accuracy: 0.7482 - val_loss: 1.2942\n",
            "Epoch 71/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.0950 - val_accuracy: 0.7537 - val_loss: 1.2695\n",
            "Epoch 72/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.0903 - val_accuracy: 0.7432 - val_loss: 1.3556\n",
            "Epoch 73/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.1045 - val_accuracy: 0.7525 - val_loss: 1.3118\n",
            "Epoch 74/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0824 - val_accuracy: 0.7514 - val_loss: 1.3765\n",
            "Epoch 75/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9699 - loss: 0.0894 - val_accuracy: 0.7466 - val_loss: 1.4105\n",
            "Epoch 76/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.0774 - val_accuracy: 0.7345 - val_loss: 1.4789\n",
            "Epoch 77/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.0817 - val_accuracy: 0.7409 - val_loss: 1.4774\n",
            "Epoch 78/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0772 - val_accuracy: 0.7490 - val_loss: 1.4781\n",
            "Epoch 79/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0742 - val_accuracy: 0.7464 - val_loss: 1.4818\n",
            "Epoch 80/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0647 - val_accuracy: 0.7452 - val_loss: 1.4670\n",
            "Epoch 81/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0739 - val_accuracy: 0.7454 - val_loss: 1.5459\n",
            "Epoch 82/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0672 - val_accuracy: 0.7387 - val_loss: 1.5836\n",
            "Epoch 83/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9760 - loss: 0.0698 - val_accuracy: 0.7467 - val_loss: 1.5314\n",
            "Epoch 84/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0559 - val_accuracy: 0.7428 - val_loss: 1.5469\n",
            "Epoch 85/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0601 - val_accuracy: 0.7500 - val_loss: 1.5674\n",
            "Epoch 86/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0615 - val_accuracy: 0.7337 - val_loss: 1.7608\n",
            "Epoch 87/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.0838 - val_accuracy: 0.7280 - val_loss: 1.7659\n",
            "Epoch 88/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0735 - val_accuracy: 0.7365 - val_loss: 1.6774\n",
            "Epoch 89/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0635 - val_accuracy: 0.7449 - val_loss: 1.6627\n",
            "Epoch 90/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0583 - val_accuracy: 0.7397 - val_loss: 1.7328\n",
            "Epoch 91/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.0545 - val_accuracy: 0.7449 - val_loss: 1.7093\n",
            "Epoch 92/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0492 - val_accuracy: 0.7347 - val_loss: 1.8681\n",
            "Epoch 93/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0483 - val_accuracy: 0.7438 - val_loss: 1.7566\n",
            "Epoch 94/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0580 - val_accuracy: 0.7431 - val_loss: 1.6848\n",
            "Epoch 95/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0462 - val_accuracy: 0.7481 - val_loss: 1.7767\n",
            "Epoch 96/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0607 - val_accuracy: 0.7489 - val_loss: 1.7160\n",
            "Epoch 97/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0411 - val_accuracy: 0.7454 - val_loss: 1.7652\n",
            "Epoch 98/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0511 - val_accuracy: 0.7430 - val_loss: 1.8327\n",
            "Epoch 99/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0338 - val_accuracy: 0.7455 - val_loss: 1.8206\n",
            "Epoch 100/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0648 - val_accuracy: 0.7430 - val_loss: 1.7973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ef9b0511120>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfQIms9UDO0T",
        "outputId": "ff7a0c63-fa5b-4f57-8e5f-e3f5e512c30e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 4ms/step - accuracy: 0.7430 - loss: 1.7973\n",
            "Test accuracy: 0.7430\n"
          ]
        }
      ]
    }
  ]
}